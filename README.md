
# ğŸŒ COVID-19 Data Engineering Pipeline (2022)

This project demonstrates a complete data engineering workflow that extracts, stores, transforms, and visualizes global COVID-19 data for the year 2022. The pipeline leverages public APIs, cloud storage, and data warehouse tools to deliver a scalable, production-ready data system.

---

## ğŸ”§ Tech Stack

- **Python** â€“ API integration and data formatting
- **REST API** â€“ [COVID-19 API](https://covid-api.com/api/reports/total)
- **AWS S3** â€“ Raw data storage
- **Snowflake** â€“ Data warehouse, transformation, and analytics
- **Snowpark (Python API)** â€“ In-warehouse data transformations
- **SQL** â€“ Data modeling, joins, and enrichment
- **Tableau** â€“ Data visualization

---

## ğŸ—‚ï¸ Project Architecture

```
         +-------------+        +--------------+        +---------------------+
         | COVID API   | -----> | Python Script | -----> | AWS S3 (Raw CSVs)   |
         +-------------+        +--------------+        +---------------------+
                                                            |
                                                            v
                                                   +----------------+
                                                   | Snowflake Stage |
                                                   +----------------+
                                                            |
                                                            v
                                          +----------------------------------+
                                          | Snowflake STAGING â†’ RAW â†’ CURATED|
                                          +----------------------------------+
                                                            |
                                                            v
                                          +----------------------------+
                                          | Tableau Dashboard          |
                                          +----------------------------+
```

---

## ğŸ§ª Features

- âœ… **Automated Data Extraction** from COVID-19 API for each country and each month of 2022.
- âœ… **Data Storage in S3** as monthly `.csv` files using Python.
- âœ… **Ingestion into Snowflake** via external stage and `COPY INTO` statements.
- âœ… **Data Enrichment** using ISO country code mappings.
- âœ… **Snowpark Transformations** for schema cleaning and final table generation.
- âœ… **Interactive Dashboards** showing confirmed cases, deaths, active cases, and fatality rates by country.

---

## ğŸ“ Folder Structure

```bash
.
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ covid_api.py          # Extracts monthly country-level COVID data to AWS S3
â”‚
â”œâ”€â”€ snowflake/
â”‚   â”œâ”€â”€ s3_snowflake.sql           # Table DDLs: STAGING, RAW, CURATED
â”‚   â”œâ”€â”€ staging_raw.py          # Snowpark script to load and transform data
â”‚   â””â”€â”€ transformed.sql          # Enrich CURATED data with country names
â”‚
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ Tableau_Dashboard.png      
â”‚
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

1. Clone the repo and set up a virtual environment.
2. Run the API extraction script:
   ```bash
   python3 scripts/covid_api.py
   ```
3. Load data into Snowflake using:
   - `snowflake/s3_snowflake.sql`
   - `snowflake/staging_raw.py`
   - `snowflake/transformed.sql`
4. Connect Tableau to your CURATED table.



## ğŸ“Œ Learning Outcomes

- Hands-on experience with real-world data engineering tools.
- Working knowledge of API-based ingestion, staging architecture, and Snowflake pipeline design.
- Practical use of Snowpark for scalable data transformation.
- Enhanced data storytelling via dashboards and KPI tracking.

---

## ğŸ§  Future Improvements

- Schedule automated daily loads via Airflow or AWS Lambda.
- Add unit tests and logging to Python scripts.
- Include historical data at region or state level.


## ğŸ™Œ Acknowledgments

Thanks to [covid-api.com](https://covid-api.com) for providing free COVID-19 data.
